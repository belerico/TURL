{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "\n",
    "This notebook is designed to preprocess a subset of SemTab challenge data, in particular the ones from this paper: https://scholar.google.com/citations?view_op=view_citation&hl=it&user=SqU0PwIAAAAJ&sortby=pubdate&citation_for_view=SqU0PwIAAAAJ:Y0pCki6q_DkC.\n",
    "\n",
    "The data is in raw format and the objective of the pre-processing is to collect the description, the name and the candidates of every entity and prepare the data to be ingested by TURL (https://arxiv.org/abs/2006.14806)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import ast\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "from operator import add, itemgetter\n",
    "from typing import Any, Dict, List\n",
    "from urllib.parse import unquote\n",
    "\n",
    "import findspark\n",
    "import pyspark\n",
    "from pandarallel import pandarallel\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import Row\n",
    "\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=64, use_memory_fs=True)\n",
    "\n",
    "import mapply\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "mapply.init(n_workers=64, chunk_size=1, max_chunks_per_worker=0, progressbar=True)\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wikidata_lookup(query: Any, retry: int = 3, dbpedia_types: Dict[str, List[str]] | None = None):\n",
    "    service_url = (\n",
    "        \"https://www.wikidata.org/w/api.php?action=wbsearchentities&search={}&language=en&limit=50&format=json\"\n",
    "    )\n",
    "    if query != \"\":\n",
    "        try:\n",
    "            url = service_url.format(urllib.parse.quote(str(query)))\n",
    "        except Exception:\n",
    "            print(query)\n",
    "            return [query, []]\n",
    "        for _ in range(retry):\n",
    "            try:\n",
    "                response = urllib.request.urlopen(url)\n",
    "            except urllib.error.HTTPError as e:\n",
    "                if e.code == 429 or e.code == 503:\n",
    "                    response = e.code\n",
    "                    time.sleep(1)\n",
    "                    continue\n",
    "                else:\n",
    "                    response = e.code\n",
    "                    break\n",
    "            except urllib.error.URLError as e:\n",
    "                response = None\n",
    "                break\n",
    "            else:\n",
    "                response = json.loads(response.read())\n",
    "                break\n",
    "        if isinstance(response, dict):\n",
    "            response = [\n",
    "                [\n",
    "                    z.get(\"id\"),\n",
    "                    z.get(\"label\", \"\"),\n",
    "                    z.get(\"description\", \"\"),\n",
    "                    dbpedia_types.get(z.get(\"id\"), []) if dbpedia_types is not None else [],\n",
    "                ]\n",
    "                for z in response.get(\"search\", [])\n",
    "            ]\n",
    "        else:\n",
    "            response = []\n",
    "    else:\n",
    "        response = []\n",
    "    return [query, response]\n",
    "\n",
    "\n",
    "def lamapi_lookup(\n",
    "    query: Any,\n",
    "    retry: int = 3,\n",
    "    dbpedia_types: Dict[str, List[str]] | None = None,\n",
    "    fuzzy: bool = False,\n",
    "):\n",
    "    service_url = (\n",
    "        \"http://149.132.176.50:8097/lookup/entity-retrieval?name={}&token=insideslab-lamapi-2024&kg=wikidata&fuzzy={}\"\n",
    "    )\n",
    "    if query != \"\":\n",
    "        try:\n",
    "            url = service_url.format(urllib.parse.quote(str(query)), fuzzy)\n",
    "        except Exception:\n",
    "            print(query)\n",
    "            return [query, []]\n",
    "        for _ in range(retry):\n",
    "            try:\n",
    "                response = urllib.request.urlopen(url)\n",
    "            except urllib.error.HTTPError as e:\n",
    "                if e.code == 429 or e.code == 503:\n",
    "                    response = e.code\n",
    "                    time.sleep(1)\n",
    "                    continue\n",
    "                else:\n",
    "                    response = e.code\n",
    "                    break\n",
    "            except urllib.error.URLError as e:\n",
    "                response = None\n",
    "                break\n",
    "            else:\n",
    "                response = json.loads(response.read())\n",
    "                break\n",
    "        if isinstance(response, dict):\n",
    "            response = [\n",
    "                [\n",
    "                    z.get(\"id\"),\n",
    "                    z.get(\"name\", \"\"),\n",
    "                    z.get(\"description\", \"\"),\n",
    "                    dbpedia_types.get(z.get(\"id\"), []) if dbpedia_types is not None else [],\n",
    "                    z.get(\"es_score\", 0.0),\n",
    "                    z.get(\"ed_score\", 0.0),\n",
    "                    z.get(\"cosine_similarity\", 0.0),\n",
    "                ]\n",
    "                for z in response.get(str(query).lower(), [])\n",
    "            ]\n",
    "            response = sorted(response, key=lambda l: (float(l[-3]), float(l[-2]), float(l[-1])), reverse=True)\n",
    "            response = response[:50]\n",
    "            response = [z[:-3] for z in response]\n",
    "        else:\n",
    "            response = []\n",
    "    else:\n",
    "        response = []\n",
    "    return [query, response]\n",
    "\n",
    "\n",
    "def wikidata_description_from_qids(qid: str, retry: int = 3) -> str:\n",
    "    service_url = \"https://www.wikidata.org/w/api.php?action=wbgetentities&ids={}&languages=en&format=json\"\n",
    "    url = service_url.format(urllib.parse.quote(qid))\n",
    "    if qid.lower() == \"nil\":\n",
    "        return \"\"\n",
    "    for _ in range(retry):\n",
    "        try:\n",
    "            response = urllib.request.urlopen(url)\n",
    "        except urllib.error.HTTPError as e:\n",
    "            if e.code == 429 or e.code == 503:\n",
    "                response = e.code\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "            else:\n",
    "                response = e.code\n",
    "                break\n",
    "        except urllib.error.URLError as e:\n",
    "            response = None\n",
    "            break\n",
    "        else:\n",
    "            response = json.loads(response.read())\n",
    "            break\n",
    "    if isinstance(response, dict):\n",
    "        try:\n",
    "            desc = response.get(\"entities\", \"\")[qid].get(\"descriptions\", {}).get(\"en\", {}).get(\"value\", \"\")\n",
    "        except Exception:\n",
    "            print(response)\n",
    "            raise Exception()\n",
    "    else:\n",
    "        desc = \"\"\n",
    "    return desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()\n",
    "conf = pyspark.SparkConf().setAll(\n",
    "    [\n",
    "        (\"spark.executor.memory\", \"8g\"),\n",
    "        (\"spark.executor.cores\", \"2\"),\n",
    "        (\"spark.executor.instances\", \"7\"),\n",
    "        (\"spark.driver.memory\", \"150g\"),\n",
    "        (\"spark.driver.maxResultSize\", \"100g\"),\n",
    "        (\"spark.driver.extraClassPath\", \"/home/fbelotti/Downloads/sqlite-jdbc-3.36.0.3.jar\"),\n",
    "    ]\n",
    ")\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_lookup(\"Advance Australia Fair*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamapi_lookup(\"Advance Australia Fair*\", fuzzy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing dataset\n",
    "\n",
    "We start by reading the ground-truth dataset from the challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The table_type for file saving\n",
    "table = \"Round1_T2D\"\n",
    "table_type = table.lower()\n",
    "\n",
    "# The path to the file containing the ground-truth\n",
    "gt_path = \"~/semtab-data/raw/Round1_T2D/gt/CEA_Round1_gt_WD.csv\".format(table)\n",
    "# gt_path = \"~/semtab-data/raw/HardTablesR2/gt/cea.csv\"\n",
    "# gt_path = \"~/semtab-data/raw/HardTablesR3/gt/cea.csv\"\n",
    "# gt_path = \"~/semtab-data/raw/2T_Round4/gt/cea.csv\"\n",
    "# gt_path = \"~/semtab-data/raw/Round3_2019/gt/CEA_Round3_gt_WD.csv\"\n",
    "# gt_path = \"~/semtab-data/raw/Round4_2020/gt/cea.csv\"\n",
    "\n",
    "# The path to the real tables folder\n",
    "tables_folder = \"~/semtab-data/raw/{}/tables/\".format(table)\n",
    "\n",
    "# Expand the paths\n",
    "tables_folder = os.path.expanduser(tables_folder)\n",
    "gt_path = os.path.expanduser(gt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `names` could be different for different datasets\n",
    "gt_df = pd.read_csv(gt_path, encoding=\"utf-8\", names=[\"tableName\", \"row\", \"col\", \"id\"])\n",
    "gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df[\"id\"].at[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df[\"id\"] = gt_df[\"id\"].astype(str).apply(lambda x: [qid.split(\"/\")[-1] for qid in x.split()][0])\n",
    "gt_df[\"tableName\"] = gt_df[\"tableName\"].astype(str)\n",
    "gt_df[\"row\"] = gt_df[\"row\"].astype(int) - 1  # Do not consider the header\n",
    "gt_df[\"col\"] = gt_df[\"col\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.read_csv(os.path.join(tables_folder, gt_df[\"tableName\"].at[0]) + \".csv\", encoding=\"utf-8\")\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mentions for each table\n",
    "table_names = gt_df[\"tableName\"].unique()\n",
    "for table_name in tqdm(table_names):\n",
    "    table_path = os.path.join(tables_folder, table_name + \".csv\")\n",
    "    table = pd.read_csv(table_path, encoding=\"utf-8\")\n",
    "    for i, row in gt_df[gt_df[\"tableName\"] == table_name].iterrows():\n",
    "        gt_df.at[i, \"mention\"] = table.iloc[row[\"row\"], row[\"col\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop rows without a mention to be linked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df.dropna(subset=[\"mention\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_number_of_mentions = len(gt_df)\n",
    "total_number_of_mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the types from the dbpedia_types mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can create the index-enwiki dump use this library https://github.com/jcklie/wikimapper\n",
    "wikipedia_wikidata_mapping = (\n",
    "    spark.read.format(\"jdbc\")\n",
    "    .options(\n",
    "        url=\"jdbc:sqlite:/home/fbelotti/turl-data/index_enwiki-20190420.db\",\n",
    "        driver=\"org.sqlite.JDBC\",\n",
    "        dbtable=\"mapping\",\n",
    "    )\n",
    "    .load()\n",
    ")\n",
    "wikipedia_wikidata_mapping.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbpedia_types = dict(\n",
    "    spark.createDataFrame(\n",
    "        sc.textFile(\"/home/fbelotti/turl-data/dbpedia_types/2019_08_30/instance_type_en.ttl\")\n",
    "        .map(lambda x: x.split())\n",
    "        .map(\n",
    "            lambda x: Row(\n",
    "                wikipedia_title=unquote(x[0][1:-1]).replace(\"http://dbpedia.org/resource/\", \"\"),\n",
    "                type=x[2][1:-1].split(\"/\")[-1],\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    .join(wikipedia_wikidata_mapping, \"wikipedia_title\", \"inner\")\n",
    "    .rdd.map(lambda x: (x[\"wikidata_id\"], [x[\"type\"]]))\n",
    "    .reduceByKey(add)\n",
    "    .collect()\n",
    ")\n",
    "print(len(dbpedia_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df[\"types\"] = gt_df[\"id\"].parallel_apply(lambda x: dbpedia_types.get(x, []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save gt dataset pre-processed (i.e. with types every mention already computed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df.to_csv(os.path.join(os.path.dirname(gt_path), \"cea_gt_with_types.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get description for every QID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qids = pd.DataFrame(gt_df[\"id\"].unique(), columns=[\"id\"])\n",
    "qids[\"description\"] = qids.parallel_apply(lambda row: wikidata_description_from_qids(row[\"id\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = gt_df.merge(qids, on=\"id\", how=\"left\")\n",
    "gt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save gt dataset pre-processed (i.e. with types and description for every mention already computed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df.to_csv(os.path.join(os.path.dirname(gt_path), \"cea_gt_with_types_and_desc.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = pd.read_csv(os.path.join(os.path.dirname(gt_path), \"cea_gt_with_types_and_desc.csv\"))\n",
    "gt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get candidates for every mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_mentions = gt_df.drop_duplicates(subset=[\"mention\"])\n",
    "unique_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = \"lamapi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lookup == \"wikidata\":\n",
    "    unique_mentions.loc[:, \"candidates\"] = unique_mentions.parallel_apply(\n",
    "        lambda row: wikidata_lookup(row[\"mention\"], dbpedia_types=dbpedia_types)[1], axis=1\n",
    "    )\n",
    "elif lookup == \"lamapi\":\n",
    "    unique_mentions.loc[:, \"candidates\"] = unique_mentions.parallel_apply(\n",
    "        lambda row: lamapi_lookup(row[\"mention\"], dbpedia_types=dbpedia_types, fuzzy=False)[1], axis=1\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(\"Invalid lookup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_mentions.to_csv(os.path.join(os.path.dirname(gt_path), \"unique_mentions_{}.csv\".format(lookup)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_mentions[unique_mentions[\"candidates\"].apply(len) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_mentions_with_candidates = {}\n",
    "for i, row in tqdm(unique_mentions.iterrows(), total=unique_mentions.shape[0]):\n",
    "    unique_mentions_with_candidates[row[\"mention\"]] = row[\"candidates\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df[\"candidates\"] = \"\"\n",
    "for i, row in tqdm(gt_df.iterrows(), total=gt_df.shape[0]):\n",
    "    cand = unique_mentions_with_candidates[row[\"mention\"]]\n",
    "    gt_df.at[i, \"candidates\"] = str(cand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df[\"candidates\"] = gt_df[\"candidates\"].parallel_apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_df[\"candidates\"] = gt_df.parallel_apply(\n",
    "#     lambda row: wikidata_lookup(row[\"mention\"], dbpedia_types=dbpedia_types)[1], axis=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df.at[0, \"candidates\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df_candidates_with_mention = gt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save gt dataset pre-processed (i.e. with types and candidates for every mention already computed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df.to_csv(\n",
    "    os.path.join(os.path.dirname(gt_path), \"cea_gt_with_wikidata_candidates_{}.csv\".format(lookup)), index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the gt file with candidates (if needed): this is the full gt dataset, without anything removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df_candidates_with_mention = pd.read_csv(\n",
    "    os.path.join(os.path.dirname(gt_path), \"cea_gt_with_wikidata_candidates_{}.csv\".format(lookup))\n",
    ")\n",
    "gt_df_candidates_with_mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df_candidates_with_mention[\"description\"] = gt_df_candidates_with_mention[\"description\"].fillna(\"\").astype(str)\n",
    "gt_df_candidates_with_mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df_candidates_with_mention[\"candidates\"] = gt_df_candidates_with_mention[\"candidates\"].parallel_apply(\n",
    "    lambda x: ast.literal_eval(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df_candidates_with_mention[\"types\"] = gt_df_candidates_with_mention[\"types\"].parallel_apply(\n",
    "    lambda x: ast.literal_eval(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset for TURL evaluation\n",
    "\n",
    "We can have two cases:\n",
    "\n",
    "1. We keep only those mentions that are contained in the candidate list generated by the wikidata lookup: in this case we evaluate the overall system\n",
    "2. If the mention is not present in the candidate list, we add it ourself: in this case we evaluate only the disambiguation model (TURL in this case) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove rows that do not contain any candidates (nothing to link to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df_candidates = gt_df_candidates_with_mention[gt_df_candidates_with_mention[\"candidates\"].apply(len).gt(0)]\n",
    "gt_df_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get only the rows where the list of candidates contains the mention (we want to test the disambiguation algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df_candidates_with_mention = gt_df_candidates[\n",
    "    gt_df_candidates.apply(lambda x: x[\"id\"] in list(map(itemgetter(0), x[\"candidates\"])), axis=1)\n",
    "]\n",
    "gt_df_candidates_with_mention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read headers from all the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_names = gt_df_candidates_with_mention[\"tableName\"].unique().tolist()\n",
    "table_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tables_names = os.listdir(tables_folder)\n",
    "headers = {}\n",
    "for table_name in tqdm(raw_tables_names):\n",
    "    if \".csv\" not in table_name:\n",
    "        continue\n",
    "    table_path = os.path.join(tables_folder, table_name)\n",
    "    headers[os.path.splitext(table_name)[0]] = (\n",
    "        pd.read_csv(os.path.join(tables_folder, table_name), nrows=0, encoding=\"utf-8\").columns.str.lower().tolist()\n",
    "    )\n",
    "headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for TURL evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_target_mention_in_candidates = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = []\n",
    "total_mention_per_table = 50\n",
    "table\n",
    "for table_name in tqdm(table_names):\n",
    "    table_sample = gt_df_candidates_with_mention[gt_df_candidates_with_mention[\"tableName\"] == table_name].sort_values(\n",
    "        [\"row\", \"col\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Table-meta information\n",
    "    page_title = \"\"\n",
    "    section_title = \"\"\n",
    "    caption = \"\"\n",
    "    table_headers = list(map(str, headers[table_name]))\n",
    "\n",
    "    # Table mentions to be linked\n",
    "    all_mentions = table_sample.apply(lambda x: [[int(x[\"row\"]), int(x[\"col\"])], str(x[\"mention\"])], axis=1)\n",
    "    if len(all_mentions) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        all_mentions = all_mentions.tolist()\n",
    "\n",
    "    # Loop over `all_mentions` in chunks of `total_mention_per_table`\n",
    "    tmpt = total_mention_per_table if total_mention_per_table > 0 else len(all_mentions)\n",
    "    for i in range(0, len(all_mentions), tmpt):\n",
    "        mentions = all_mentions[i : i + tmpt]\n",
    "\n",
    "        # Create candidates for each mention\n",
    "        labels = []\n",
    "        all_candidates = []\n",
    "        entities_index = []\n",
    "        for row_idx, row in table_sample[i : i + tmpt].iterrows():\n",
    "            candidates = row[\"candidates\"]\n",
    "            try:\n",
    "                label_index = list(map(itemgetter(0), candidates)).index(row[\"id\"])\n",
    "            except ValueError:\n",
    "                if insert_target_mention_in_candidates:\n",
    "                    label_index = 0\n",
    "                    candidates = [[row[\"id\"], row[\"mention\"], row[\"description\"], row[\"types\"]]] + candidates\n",
    "                else:\n",
    "                    continue\n",
    "            label_index += len(all_candidates)\n",
    "            candidates_without_id = [x[1:] for x in candidates]\n",
    "            candidates_without_id_str = []\n",
    "            for candidate in candidates_without_id:\n",
    "                mention = str(candidate[0])\n",
    "                description = str(candidate[1])\n",
    "                types = candidate[2]\n",
    "                candidates_without_id_str.append([mention, description, types])\n",
    "            labels.append(int(label_index))\n",
    "            all_candidates.extend(candidates_without_id_str)\n",
    "            entities_index.append(list(range(len(all_candidates) - len(candidates), len(all_candidates))))\n",
    "        if len(all_candidates) != 0:\n",
    "            # print(\n",
    "            #     \"Table\",\n",
    "            #     table_name,\n",
    "            #     \"has\",\n",
    "            #     len(mentions),\n",
    "            #     \"mentions and\",\n",
    "            #     len(all_candidates),\n",
    "            #     \"candidates\",\n",
    "            # )\n",
    "            tables.append(\n",
    "                [\n",
    "                    str(table_name),\n",
    "                    page_title,\n",
    "                    section_title,\n",
    "                    caption,\n",
    "                    table_headers,\n",
    "                    mentions,\n",
    "                    all_candidates,\n",
    "                    labels,\n",
    "                    entities_index,\n",
    "                ]\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump the dataset for TURL evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Saving tables to\",\n",
    "    \"/home/fbelotti/turl-data/{}{}{}.table_entity_linking.json\".format(\n",
    "        table_type, \"_all\" if insert_target_mention_in_candidates else \"\", \"_\" + lookup\n",
    "    ),\n",
    ")\n",
    "with open(\n",
    "    \"/home/fbelotti/turl-data/{}{}{}.table_entity_linking.json\".format(\n",
    "        table_type, \"_all\" if insert_target_mention_in_candidates else \"\", \"_\" + lookup\n",
    "    ),\n",
    "    \"w\",\n",
    ") as f:\n",
    "    json.dump(tables, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process dataset with TURL ELDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.data_loader.el_data_loaders import ELDataset\n",
    "from src.utils.util import load_dbpedia_type_vocab\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_dir = \"/home/fbelotti/turl-data\"\n",
    "    type_vocab = load_dbpedia_type_vocab(data_dir)\n",
    "    train_dataset = ELDataset(\n",
    "        data_dir,\n",
    "        type_vocab,\n",
    "        max_input_tok=500,\n",
    "        src=(table_type + \"_all\" if insert_target_mention_in_candidates else table_type) + \"_\" + lookup,\n",
    "        max_length=[50, 10, 10, 100],\n",
    "        force_new=True,\n",
    "        tokenizer=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_and_candidate(tables):\n",
    "    results = []\n",
    "    # For every entity mention in the table\n",
    "    for i, entity in enumerate(tables[5]):\n",
    "        # If the candidate entities for the mention are empty, skip\n",
    "        if len(tables[8][i]) == 0:\n",
    "            continue\n",
    "        # ((table_id, entity row, entity col), [index of the candidate entity in the candidate entities list, candidate indexes, candidate entities])\n",
    "        results.append(((tables[0], entity[0][0], entity[0][1]), [tables[7][i], tables[8][i], tables[6]]))\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_tp(result):\n",
    "    result = result[1]\n",
    "    # result[0] contains: label index (in the candidate list), candidate span (in the candidate list), candidates\n",
    "    # result[1] contains: sorted predicted indexes, sorted predicted scores\n",
    "    pred = []\n",
    "    lookup = [result[0][1][0], 0]  # Lookup the first candidate\n",
    "    # The prediction is first predicted candidate\n",
    "    # TODO: consider the case where the first predicted candidate is not in the candidate span, i.e.\n",
    "    # a totally different entity has been predicted\n",
    "    for i, x in enumerate(result[1][0]):\n",
    "        if x in result[0][1]:\n",
    "            pred = [x, result[1][1][i]]\n",
    "            break\n",
    "    # Get the score of the first candidate returned by the lookup\n",
    "    for i, x in enumerate(result[1][0]):\n",
    "        if x == lookup[0]:\n",
    "            lookup[1] = result[1][1][i]\n",
    "            break\n",
    "    final = pred[0] if pred[0] == lookup[0] or (pred[1] * 1.0) > lookup[1] else lookup[0]\n",
    "    if final == result[0][0]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = \"round1_t2d_all_lamapi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/fbelotti/turl-data/\" + dataset_type + \".table_entity_linking.json\", \"rb\") as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No dedup: ~/projects/TURL/output/logs/turl/fine-tuning-el/2024-02-08_13-14-19/version_0/checkpoints/checkpoint-last/pytorch_model.bin\n",
    "# Dedup: ~/projects/TURL/output/logs/turl/fine-tuning-el/2024-02-14_11-01-08/version_0/checkpoints/checkpoint-last/pytorch_model.bin\n",
    "\n",
    "dedup = False\n",
    "if dedup:\n",
    "    prefix = \"/home/fbelotti/projects/TURL/output/logs/turl/fine-tuning-el/2024-02-14_11-01-08/version_0/test/\"\n",
    "else:\n",
    "    prefix = \"/home/fbelotti/projects/TURL/output/logs/turl/fine-tuning-el/2024-02-08_13-14-19/version_0/test/\"\n",
    "    # prefix = \"/home/fbelotti/projects/TURL/output/logs/turl/fine-tuning-el/2024-03-01_10-32-37/version_0/test/\"\n",
    "    # prefix = \"/home/fbelotti/projects/TURL/output/logs/turl/fine-tuning-el/2024-03-04_15-26-27/version_0/test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load single result file and compute true positive with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading results\", prefix + dataset_type + \"_entity_linking_results{}.pkl\".format(\"_dedup\" if dedup else \"\"))\n",
    "with open(\n",
    "    prefix + dataset_type + \"_entity_linking_results{}.pkl\".format(\"_dedup\" if dedup else \"\"),\n",
    "    \"rb\",\n",
    ") as f:\n",
    "    test_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results for table with name\n",
    "test_results[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All mentions in the table with name test_results[0][0], number of mentions\n",
    "print(len(test_results[0][1]), \"mentions in table\", test_results[0][0], \"\\n\", test_results[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorted indexes for every mention in the table with name test_results[0][0]\n",
    "len(test_results[0][2][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_labels_and_cands = sc.parallelize(dataset).flatMap(get_labels_and_candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_and_results = dataset_labels_and_cands.join(\n",
    "    sc.parallelize(test_results).flatMap(\n",
    "        lambda x: [((x[0], z[0], z[1]), (x[2][i], x[3][i])) for i, z in enumerate(x[1])]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_tp = dataset_and_results.map(get_tp).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predicted = 0\n",
    "for table in dataset:\n",
    "    all_predicted += len(table[5])\n",
    "all_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the split results and compute the true positive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {}\n",
    "for table in tqdm(dataset):\n",
    "    table_id = table[0]\n",
    "    table_mentions = table[5]\n",
    "    table_labels = table[7]\n",
    "    table_entities_index = table[8]\n",
    "    if table_id not in dataset_dict:\n",
    "        dataset_dict[table_id] = {}\n",
    "    for i, mention in enumerate(table_mentions):\n",
    "        if (mention[0][0], mention[0][1]) in dataset_dict[table_id]:\n",
    "            print(\"Duplicate mention in table\", table_id, \"at row\", mention[0][0], \"and col\", mention[0][1])\n",
    "        dataset_dict[table_id][(mention[0][0], mention[0][1])] = (table_labels[i], tuple(table_entities_index[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix + dataset_type + \"_entity_linking_results{}_split*.pkl\".format(\"_dedup\" if dedup else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob(prefix + dataset_type + \"_entity_linking_results{}_split*.pkl\".format(\"_dedup\" if dedup else \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_tp = 0\n",
    "all_test_files = glob.glob(\n",
    "    prefix + dataset_type + \"_entity_linking_results{}_split*.pkl\".format(\"_dedup\" if dedup else \"\")\n",
    ")\n",
    "for file in tqdm(all_test_files):\n",
    "    with open(file, \"rb\") as f:\n",
    "        test_results = pickle.load(f)\n",
    "    for table in tqdm(test_results):\n",
    "        for i, (row, col) in enumerate(table[1]):\n",
    "            r = dataset_dict[table[0]][(row, col)]\n",
    "            our_tp += get_tp([[], [r, [table[2][i], table[3][i]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predicted = 0\n",
    "for table in dataset_dict.keys():\n",
    "    all_predicted += len(dataset_dict[table].keys())\n",
    "all_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gt_df), all_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gt = len(gt_df)\n",
    "prec = our_tp / all_predicted\n",
    "rec = our_tp / all_gt\n",
    "f1 = 2 * (prec * rec) / (prec + rec)\n",
    "all_predicted, all_gt, f1, prec, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "turl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
